# Processed HuggingFace Dataset

This folder originally contained the processed HuggingFace `Dataset` object converted from the full RecipeNLG dataset. However, due to file size limits on GitHub, only key metadata and a sample are included here.

## Contents

- `processed_dataset_sample.csv`: A sample CSV containing a small subset of the processed dataset.
- `dataset_info.json`: Metadata about the dataset, including column information and format.
- `state.json`: State information for HuggingFace dataset loading.

The full `.arrow` files (binary data files for HuggingFace datasets) could not be uploaded due to size constraints.

## How to Rebuild

To fully recreate the processed dataset:

1. Download the original `full_dataset.csv` from the [RecipeNLG Website](https://recipenlg.cs.put.poznan.pl/).
2. Preprocess the data using the provided script:
   ```bash
   python scripts/download_and_convert.py
   ```
   
or manually:
  ```python
  from datasets import load_dataset
  dataset = load_dataset("csv", data_files="path/to/full_dataset.csv")
  dataset.save_to_disk("path/to/save/processed_hf_dataset")
   ```

3. The processed dataset will be saved with .arrow files for efficient loading by HuggingFace.

## Notes:
- The provided sample CSV (`processed_dataset_sample.csv`) shows the data format after processing.
- `dataset_info.json` and `state.json` are automatically generated by HuggingFace's `save_to_disk()` and help with reconstructing the dataset.
